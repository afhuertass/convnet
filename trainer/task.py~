



import cnn_model as cnn_maker
import data_manager as dm



from tensorflow.contrib import learn
from tensorflow.contrib.metrics.python.ops import metric_ops
import argparse


import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)


def metric_log_fn ( predictions , labels , weights = 1.0) :
    # funcion para calcular la log_loss
    loss = tf.losses.log_loss (
            predictions = result , labels = labels
        )
    return loss 
def run_evaluate( args ):
    # todo : implement this
    return ""

def run_train( args ):

   
    tensors_to_log = { "probabilities":"softmax_tensor"  }

    logging_hook = tf.train.LoggingTensorHook(
        tensors = tensors_to_log , every_n_iter = 50
    )
    
    train_input_fn = dm.make_input_fn(
         args.train_data_path  ,
        dm.parse_examples ,
        args.batch_size ,
        num_epochs = args.num_epochs
    )
    cnn_model = cnn_maker.make_model( args.learning_rate )
    
    cancer_model = learn.Estimator(
        model_fn = cnn_model , model_dir = args.output_path
    )
    
    cancer_model.fit(
        input_fn = train_input_fn  ,
        steps = args.num_epochs 
    )
    
    
    
    metrics = {
        "accuracy": learn.MetricSpec(
            metric_fn = tf.metrics.accuracy , prediction_key="probabilities"
        ) , 
        "log_loss" : learn.MetricSpec (
            metric_fn = metric_ops.streaming_mean , prediction_key = "loss"
        )
    } 
    

    #cancer_model.evaluate(
     #   input_fn = train_input_fn ,
     #   metrics = metrics 
    #)

def model_arguments(parser):

    group = parser.add_argument_group(
        title = "Model arguments" ,
        description = " model arguments, in this case the learning rate, which will be used by the hyperparameter tunnning engine by google ml. pass it a --learning-rate xxx"
    )

    group.add_argument( '--learning-rate' , type=float , default=0.01)

    return group

def path_arguments(parser):

    group = parser.add_argument_group(title= "Data paths for training")

    group.add_argument(
        '--train-data-path' ,
        type = str ,
        required = True,
        nargs = '+',
        help = 'Path to training data, local or GCS'
    )

    group.add_argument(
        '--output-path' ,
        type = str,
        required = True ,
        help = "path to save the output of the model, checkpoints and others. could be local or GCS"
    )

    return group

def end_arguments(parser):

    group = parser.add_argument_group(title= "Termination arguments")

    group.add_argument(
        '--num-epochs' ,
        type = int ,
        required = True,
        help = "Number of epochs to run the model "
    )
    return group 

def training_arguments(parser):

    group = parser.add_argument_group(title= "Training arguments")

    group.add_argument(
        '--batch-size' ,
        type = int,
        default = 64 ,
        help = "Number units  of processed per min batch "
    )
    group.add_argument(
        '--job-dir' ,
        type=str,
        help = "not used at the moment but required because im an idiot"
    )

    return group
if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    model_arguments( parser )
    path_arguments( parser )
    end_arguments( parser ) 
    training_arguments(parser )
    
    run_train(  parser.parse_args() )
    
    print("train")
